{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f88a310-2471-4ead-8b7f-e9ec11584bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_percent_of_artilces(products,grouping_column,constrained_on='',constraint='',exclusions=[]):\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    if constrained_on!='':\n",
    "        products=products.query(constrained_on+' == '+constraint)\n",
    "             \n",
    "    df = (\n",
    "        products\n",
    "        .groupby(grouping_column)\n",
    "        .agg({\"article_id\": \"count\"})\n",
    "        .rename({\"article_id\": \"counts\"}, axis=1) \n",
    "        .query(grouping_column+\" not in @exclusions\")   \n",
    "    )\n",
    "\n",
    "    df=df.assign(totals=df.counts.sum())\n",
    "    df=df.assign(percent_of_products=df.counts/df.totals)\n",
    "    df=df.drop(['counts','totals'], axis=1)\n",
    "    df=df.rename({'percent_of_products':'percent_of_products_'+constraint[1:-1]},axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbaf804-8e3c-47c0-9e06-810a6be85a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergings(leftie,rightie,ons):\n",
    "    '''\n",
    "    '''\n",
    "    if not isinstance(leftie, pd.DataFrame):\n",
    "        return rightie\n",
    "    else:\n",
    "        return leftie.merge(rightie, how='outer',on=ons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4921d26-d83e-40fb-b65a-7e735dab6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sales_breakdown(products, constrained_on,grouping_column,exclusions,ordered_list):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    new_df=''\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(15)\n",
    "\n",
    "    #loop through the \n",
    "    for i in pd.unique(products[constrained_on]):\n",
    "        constraint='\"'+i+'\"'\n",
    "        \n",
    "        df=generating_percent_of_artilces(products,grouping_column,constrained_on,constraint,exclusions)\n",
    "        \n",
    "        # reorder if we doing the reordering\n",
    "        if ordered_list:\n",
    "            df = df.loc[ordered_list]\n",
    "        \n",
    "        #function that only merges if left database exists\n",
    "        new_df=mergings(new_df,df,grouping_column)\n",
    "        \n",
    "        new_df=new_df.fillna(0)\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.plot(new_df.index, new_df['percent_of_products_'+constraint[1:-1]],label=constraint[1:-1])\n",
    "\n",
    "    plt.title('Sales by '+grouping_column)\n",
    "    plt.xlabel('Color name')\n",
    "    plt.ylabel('Percent of sales')   \n",
    "\n",
    "\n",
    "    f.legend(loc='upper left', frameon=False)\n",
    "    plt.show() \n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02f1ab2-6f11-4401-a15a-8d3b08a931f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_deciles(enhanced_products,category_name):\n",
    "    '''\n",
    "    '''\n",
    "    price_deciles = (\n",
    "        enhanced_products\n",
    "        .query(\"product_group_name=='\"+category_name+\"'\")\n",
    "        .assign(deciles=lambda d: np.floor(d.price_percentile/0.1)*0.1)\n",
    "        .groupby('deciles')\n",
    "        .agg({'price_mean':'min'})\n",
    "        .rename({'price_mean':category_name.lower().replace(' ','_')},axis=1)\n",
    "    )\n",
    "    return price_deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dade57-be20-4120-8585-d5bc3efe7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_price_deciles(contrained_on,constraint,categories,columns):\n",
    "    '''\n",
    "    '''\n",
    "    constraint='\"'+constraint+'\"'\n",
    "\n",
    "\n",
    "    if constrained_on!='':\n",
    "            ladies_enhanced_products=enhanced_products.query(constrained_on+' == '+constraint)\n",
    "\n",
    "    # ladies_enhanced_products=enhanced_products.query(\"index_group_name=='Ladieswear'\")\n",
    "\n",
    "    deciles_by_category=''\n",
    "\n",
    "    for category_name in pd.unique(products[categories]):\n",
    "        category_deciles=get_price_deciles(ladies_enhanced_products,category_name)\n",
    "\n",
    "        deciles_by_category=mergings(deciles_by_category,category_deciles,'deciles')\n",
    "\n",
    "    if columns:\n",
    "        deciles_by_category=deciles_by_category[columns]\n",
    "\n",
    "\n",
    "    return deciles_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12efaf84-837e-4065-84e7-bfacb235e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_average_price_products(product_group, product_group_filter, gender_age, gender_age_filter):\n",
    "    \n",
    "    def w_avg(df, values, weights):\n",
    "        d = df[values]\n",
    "        w = df[weights]\n",
    "        return (d * w).sum() / w.sum()\n",
    "    \n",
    "    weighted_average_price = (\n",
    "            enhanced_products\n",
    "            .query(f\"{gender_age}=='{gender_age_filter}' & {product_group}=='{product_group_filter}'\")\n",
    "\n",
    "            .groupby('product_type_name')\n",
    "            # .agg({'article_id_count':'sum'})\n",
    "            .apply(w_avg, 'price_percentile', 'article_id_count')\n",
    "            .reset_index(name='weighted_avg_price')\n",
    "        )\n",
    "\n",
    "    total_average_orders_per_category = (\n",
    "            enhanced_products\n",
    "            .query(f\"{gender_age}=='{gender_age_filter}' & {product_group}=='{product_group_filter}'\")\n",
    "\n",
    "            .groupby('product_type_name')\n",
    "            .agg({'article_id_count':['mean','sum']})\n",
    "            # .apply(w_avg, 'price_percentile', 'article_id_count')\n",
    "\n",
    "        )\n",
    "    total_average_orders_per_category.columns=['_'.join(col) for col in total_average_orders_per_category.columns.values]\n",
    "\n",
    "    merged_df=weighted_average_price.merge(total_average_orders_per_category,on='product_type_name',how='inner')\n",
    "    \n",
    "    scaled_features_sum = StandardScaler().fit_transform(please_work['article_id_count_sum'].values.reshape(-1,1))\n",
    "    scaled_features_mean = StandardScaler().fit_transform(please_work['article_id_count_mean'].values.reshape(-1,1))\n",
    "\n",
    "    scaled_features_sum_df = pd.DataFrame(scaled_features_sum, index=please_work.index, columns=['orders_sum_scaled'])\n",
    "    scaled_features_mean_df = pd.DataFrame(scaled_features_mean, index=please_work.index, columns=['orders_mean_scaled'])\n",
    "\n",
    "    adjusted_count_price=(\n",
    "                merged_df\n",
    "                .merge(scaled_features_sum_df,left_index=True, right_index=True)\n",
    "                .merge(scaled_features_mean_df,left_index=True, right_index=True)\n",
    "\n",
    "            )\n",
    "    \n",
    "    \n",
    "    ax1 = adjusted_count_price.plot.scatter(x='weighted_avg_price', y='orders_mean_scaled')\n",
    "            # Annotate each data point\n",
    "    for i, txt in enumerate(adjusted_count_price.product_type_name):\n",
    "\n",
    "        ax1.annotate(txt, (adjusted_count_price.weighted_avg_price.iat[i]+0.01, adjusted_count_price['orders_mean_scaled'].iat[i]))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    ax2 = adjusted_count_price.plot.scatter(x='weighted_avg_price', y='orders_sum_scaled')\n",
    "            # Annotate each data point\n",
    "    for i, txt in enumerate(adjusted_count_price.product_type_name):\n",
    "\n",
    "        ax2.annotate(txt, (adjusted_count_price.weighted_avg_price.iat[i]+0.01, adjusted_count_price['orders_sum_scaled'].iat[i]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adjusted_count_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd6e96-ecbb-4778-944d-109f3496fa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
